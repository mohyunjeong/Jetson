{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Face Detection\n",
    "- Face Tracking 진행 예정!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ 1. 카메라 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera # 카메라 관련 라이브러리\n",
    "from jetbot import bgr8_to_jpeg # bgr type -> jpeg 변환\n",
    "\n",
    "camera = Camera.instance(width = 720, height = 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오류?\n",
    "# 1) 왼쪽 정지버튼 -> 전체 커널 셧다운\n",
    "# 2) 커널 restart\n",
    "# 3) 재부팅\n",
    "# 4) 카메라 접촉 불량 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ 2. 카메라 프리뷰 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156176fbebee4172935ffd795a81acbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='300', width='300')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets #파이썬에서 위젯을 활용할 수 있는 라이브러리\n",
    "from IPython.display import display #실제 이미지를 display할 수 있는 라이브러리\n",
    "\n",
    "detect_face = widgets.Image(width = 300, height = 300, format = 'jpeg') # 인식될 공간\n",
    "\n",
    "display(detect_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카메라 테스트\n",
    "\n",
    "while 1:\n",
    "    detect_face.value = bgr8_to_jpeg(camera.value) # 카메라 값을 변환시킨다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ 학습된 모델을 가져오자!! \n",
    "\n",
    "- https://github.com/opencv/opencv/tree/master/data/haarcascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "100  908k  100  908k    0     0   187k      0  0:00:04  0:00:04 --:--:--  289k\n"
     ]
    }
   ],
   "source": [
    "# curl 명령어 통해서 링크로 학습된 데이터 가져오기!\n",
    "# 터미널창 sudo apt-get install curl\n",
    "!curl -L -O https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "face_x = face_y = face_w = face_h = 0 # 얼굴을 표시할 좌표를 0으로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    frame = camera.value\n",
    "    \n",
    "    cv2.resize(frame, (300, 300)) # 학습된 데이터의 이미지가 300*300 픽셀\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # 흑백으로 변경\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray) # 흑백 이미지 내에서 얼굴 검출\n",
    "    \n",
    "    if len(faces) > 0 : # 만약 검출된게 있다면\n",
    "        (face_x, face_y, face_w, face_h) = faces[0] # 사진에 좌표 생성\n",
    "        \n",
    "        # 직사각형 그리기!\n",
    "        cv2.rectangle(frame, (face_x, face_y), (face_x + face_w, face_y + face_h), (0, 0, 255), 4) # 직사각형 생성 # (0, 0, 255) -> 빨강\n",
    "    \n",
    "    detect_face.value = bgr8_to_jpeg(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ 눈 검출!\n",
    "- ROT(Region of Interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  333k  100  333k    0     0   184k      0  0:00:01  0:00:01 --:--:-- 14.2M\n"
     ]
    }
   ],
   "source": [
    "# 눈 관련 학습 모델 가져오기!\n",
    "!curl -L -O https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_eye.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 눈 관련 cascade 모델 생성!\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# 눈 좌표 초기화\n",
    "\n",
    "eye_x = eye_y = eye_w = eye_h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "while 1:\n",
    "    frame = camera.value\n",
    "    \n",
    "    cv2.resize(frame, (300, 300)) # 학습된 데이터의 이미지가 300*300 픽셀\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # 흑백으로 변경\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray) # 흑백 이미지 내에서 얼굴 검출\n",
    "    \n",
    "    if len(faces) > 0 : # 만약 검출된게 있다면\n",
    "        (face_x, face_y, face_w, face_h) = faces[0] # 사진에 좌표 생성\n",
    "        \n",
    "        # 직사각형 그리기!\n",
    "        \n",
    "        cv2.rectangle(frame, (face_x, face_y), (face_x + face_w, face_y + face_h), (0, 0, 255), 4)\n",
    "        # 직사각형 생성 # (0, 0, 255) -> 빨강\n",
    "        \n",
    "        # 눈이 검출된다 -> 먼저 얼굴이 검출되어야 함\n",
    "        \n",
    "        roi_region = gray[face_y : face_y + face_h, face_x : face_x + face_w]\n",
    "                     # -> gray 전체 프레임에서 얼굴 영역만 슬라이싱\n",
    "            \n",
    "        roi_color = frame[face_y : face_y + face_h, face_x : face_x + face_w]\n",
    "                    # -> 눈을 표시할 수 있는 도형을 컬러 프레임에 찍기 위함! # 원본 -> frame\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_region) # 눈 검출\n",
    "        \n",
    "        # 눈이 검출되었다면! \n",
    "        \n",
    "        for eye_x, eye_y, eye_w, eye_h in eyes : # 눈이라고 인식된 모든 공간\n",
    "            cv2.rectangle(roi_color, (eye_x, eye_y), (eye_x + eye_w, eye_y + eye_h), (255, 0, 0), 2)\n",
    "            # (255, 0, 0) -> 파랑\n",
    "    \n",
    "    detect_face.value = bgr8_to_jpeg(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serial Open!\n"
     ]
    }
   ],
   "source": [
    "from servoserial import ServoSerial\n",
    "\n",
    "servo = ServoSerial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chmod -> change mode\n",
    "# 리눅스의 권한을 주는 방식\n",
    "# shdo chmod 777 /dev/ttyTHS1\n",
    "# ____ _____ _____ read, write, execute\n",
    "# user group other\n",
    "# 111 101 001 -> sudo chmod 751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\t`\\x00\\n\\x02\\x084\\x00\\n\\x86'\n"
     ]
    }
   ],
   "source": [
    "# 내 로봇 머리의 중앙값 찾기\n",
    "# 1번 인덱스 좌우(600 ~ 3600), 2번 인덱스 상하(1300 ~ 4095)\n",
    "\n",
    "servo.Servo_serial_double_control(1, 2400, 2, 2100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내 로봇 머리의 중앙 값\n",
    "\n",
    "center_x = 2400\n",
    "center_y = 2100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ PID(비례 - 적분 - 미분)\n",
    "- 카메라가 얼굴 탐지 영역의 중심점을 찾아가는데 \n",
    "- 어느정도로 움직여야할지 그 정도를 계산하는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P (propotional : 비례)\n",
    "# - 현재 물체와 원하는 위치 사이의 오차에 비례해서 움직임을 조절\n",
    "# -> 오차가 크면 많이 움직이고 적으면 조금 움직임 -> 오차를 빠르게 줄여주는 역할\n",
    "\n",
    "# I (integral : 적분)\n",
    "# - 오랜 시간 동안 물체가 원하는 위치에 도달하지 못했을 때, 이전 오차들을 더한 후 누적해서 물체를 움직임\n",
    "# -> 오차를 완전히 없애주고 정확한 위치로 가게 함\n",
    "\n",
    "# D (derivative : 미분)\n",
    "# - 물체가 급격히 위치를 바꿀 때 이 변화를 미리 감지하고 조절\n",
    "# -> 로봇이 너무 빨리 이동하지 않게 함\n",
    "\n",
    "# -> 세가지 요소를 결합해서 로봇 머리가 사람 얼굴을 찾아 부드럽고 정확하게 따라가도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PID\n",
    "\n",
    "xservo_pid = PID.PositionalPID(1.9, 0.3, 0.35)\n",
    "yservo_pid = PID.PositionalPID(1.5, 0.2, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "b\"\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x08L\\x00\\n\\x02\\x08'\\x00\\n\\xa8\"\n",
      "7\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x07:\\x00\\n\\x02\\x06\\xdd\\x00\\n\\x07'\n",
      "247\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x06\\x9b\\x00\\n\\x02\\x06\\x8d\\x00\\n\\xf7'\n",
      "112\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x06\\xb6\\x00\\n\\x02\\x06\\xf9\\x00\\np'\n",
      "224\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x07\\x0c\\x00\\n\\x02\\x071\\x00\\n\\xe0'\n",
      "173\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x06\\x94\\x00\\n\\x02\\x06\\xde\\x00\\n\\xad'\n",
      "35\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x06r\\x00\\n\\x02\\x06\\x8a\\x00\\n#'\n",
      "47\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x07\\x00\\x00\\n\\x02\\x06\\xef\\x00\\n/'\n",
      "172\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x07\\x12\\x00\\n\\x02\\x07_\\x00\\n\\xac'\n",
      "76\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x05\\xc1\\x00\\n\\x02\\x06\\x13\\x00\\nL'\n",
      "153\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x05i\\x00\\n\\x02\\x06\\x1e\\x00\\n\\x99'\n",
      "44\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x04\\xfe\\x00\\n\\x02\\x05\\xf8\\x00\\n,'\n"
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    frame = camera.value\n",
    "    \n",
    "    cv2.resize(frame, (300, 300)) # 학습된 데이터의 이미지가 300*300 픽셀\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # 흑백으로 변경\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray) # 흑백 이미지 내에서 얼굴 검출\n",
    "    \n",
    "    if len(faces) > 0 : # 만약 검출된게 있다면\n",
    "        (face_x, face_y, face_w, face_h) = faces[0] # 사진에 좌표 생성\n",
    "        \n",
    "        # 직사각형 그리기!\n",
    "        \n",
    "        cv2.rectangle(frame, (face_x, face_y), (face_x + face_w, face_y + face_h), (0, 0, 255), 4)\n",
    "        # 직사각형 생성 # (0, 0, 255) -> 빨강\n",
    "        \n",
    "        # X축\n",
    "        \n",
    "        xservo_pid.SystemOutput = face_x + face_w / 2 # 얼굴의 x축 중심점\n",
    "        xservo_pid.SetStepSignal(150) # 단계 신호 설정 -> 얼굴까지 얼마나 빠르게 움직여야 되는가! -> 150이면 빠른 정도\n",
    "        xservo_pid.SetInertiaTime(0.01, 0.006) # 관성시간 -> 변화에 대해서 얼마나 빠르게 대응!\n",
    "        target_x = int(center_x + xservo_pid.SystemOutput)\n",
    "        \n",
    "        # Y축\n",
    "        yservo_pid.SystemOutput = face_y + face_h / 2 # 얼굴의 x축 중심점\n",
    "        yservo_pid.SetStepSignal(150) # 단계 신호 설정 -> 얼굴까지 얼마나 빠르게 움직여야 되는가! -> 150이면 빠른 정도\n",
    "        yservo_pid.SetInertiaTime(0.01, 0.006) # 관성시간 -> 변화에 대해서 얼마나 빠르게 대응!\n",
    "        target_y = int(center_y + yservo_pid.SystemOutput)\n",
    "        \n",
    "        servo.Servo_serial_double_control(1, target_x, 2, target_y)\n",
    "        \n",
    "        # 눈이 검출된다 -> 먼저 얼굴이 검출되어야 함\n",
    "        \n",
    "        roi_region = gray[face_y : face_y + face_h, face_x : face_x + face_w]\n",
    "                     # -> gray 전체 프레임에서 얼굴 영역만 슬라이싱\n",
    "            \n",
    "        roi_color = frame[face_y : face_y + face_h, face_x : face_x + face_w]\n",
    "                    # -> 눈을 표시할 수 있는 도형을 컬러 프레임에 찍기 위함! # 원본 -> frame\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_region) # 눈 검출\n",
    "        \n",
    "        # 눈이 검출되었다면! \n",
    "        \n",
    "        for eye_x, eye_y, eye_w, eye_h in eyes : # 눈이라고 인식된 모든 공간\n",
    "            cv2.rectangle(roi_color, (eye_x, eye_y), (eye_x + eye_w, eye_y + eye_h), (255, 0, 0), 2)\n",
    "            # (255, 0, 0) -> 파랑\n",
    "    \n",
    "    detect_face.value = bgr8_to_jpeg(frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
